{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "MultiVAE_Practico.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ahq3V1FYhx"
      },
      "source": [
        "# Variational autoencoders for collaborative filtering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpghG7ADFYhy"
      },
      "source": [
        "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
        "\n",
        "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzM2Du1O1ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc397ad-cfc8-4c1d-ef2d-7ac6aaf2cc19"
      },
      "source": [
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/6d/2348df00a34baaabdef0fdb4f46f962f7a8a6720362c26c3a44a249767ea/tensorflow_gpu-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.35.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.7.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.1.7)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (1.0.post1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow-gpu==1.14) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (44.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.1)\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9EU9SzAI1Vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4a3c5c-1538-4c06-f069-6559c461c2e9"
      },
      "source": [
        "!pip install Bottleneck"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Bottleneck\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/08/278c6ee569458e168096f6b51019cc1c81c288da3d1026a22ee2ccead102/Bottleneck-1.3.2.tar.gz (88kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 25.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 21.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 11.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 81kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 7.4MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from Bottleneck) (1.16.4)\n",
            "Building wheels for collected packages: Bottleneck\n",
            "  Building wheel for Bottleneck (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Bottleneck: filename=Bottleneck-1.3.2-cp27-cp27mu-linux_x86_64.whl size=315086 sha256=1c04167a05b5d82d4a03bb6deb84b4d30abf09abe16eaf969e101dce98faa589\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/a9/12/41b13e8b44889ab05ec4dcc91f27da21634bacf2a0e87473b8\n",
            "Successfully built Bottleneck\n",
            "Installing collected packages: Bottleneck\n",
            "Successfully installed Bottleneck-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK_96uetFYhz"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
        "\n",
        "import bottleneck as bn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8jolZYFYh4"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5WFiDZRFYh5"
      },
      "source": [
        "We load the data and create train/validation/test splits following strong generalization: \n",
        "\n",
        "- We split all users into training/validation/test sets. \n",
        "\n",
        "- We train models using the entire click history of the training users. \n",
        "\n",
        "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmGA2EPQFYh6"
      },
      "source": [
        "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA4ezX8MJUA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e41be4-a281-411b-8cd6-164f30ca6db3"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
        "!unzip /content/ml-20m.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-02 00:55:04--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 198702078 (189M) [application/zip]\n",
            "Saving to: ‘ml-20m.zip’\n",
            "\n",
            "ml-20m.zip          100%[===================>] 189.50M  99.2MB/s    in 1.9s    \n",
            "\n",
            "2020-12-02 00:55:06 (99.2 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
            "\n",
            "Archive:  /content/ml-20m.zip\n",
            "   creating: ml-20m/\n",
            "  inflating: ml-20m/genome-scores.csv  \n",
            "  inflating: ml-20m/genome-tags.csv  \n",
            "  inflating: ml-20m/links.csv        \n",
            "  inflating: ml-20m/movies.csv       \n",
            "  inflating: ml-20m/ratings.csv      \n",
            "  inflating: ml-20m/README.txt       \n",
            "  inflating: ml-20m/tags.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-80sYNYFYh7"
      },
      "source": [
        "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
        "DATA_DIR = '/content/ml-20m'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnwdl8CbFYiA"
      },
      "source": [
        "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn_jtYGHFYiE"
      },
      "source": [
        "# binarize the data (only keep ratings >= 4)\n",
        "raw_data = raw_data[raw_data['rating'] > 3.5]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehnKTGiFYiJ",
        "outputId": "951a0af2-212a-4ed8-936f-ec34560ce2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  movieId  rating   timestamp\n",
              "6        1      151     4.0  1094785734\n",
              "7        1      223     4.0  1112485573\n",
              "8        1      253     4.0  1112484940\n",
              "9        1      260     4.0  1112484826\n",
              "10       1      293     4.0  1112484703"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1094785734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>223</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112485573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>253</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>260</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1112484703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzYgRQIiFYiO"
      },
      "source": [
        "### Data splitting procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qVs5EEqFYiP"
      },
      "source": [
        "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
        "- Use all the items from the training users as item set\n",
        "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDPvNl-QFYiQ"
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "    return count"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKYy5rGjFYiU"
      },
      "source": [
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "    \n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    return tp, usercount, itemcount"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWYHa34vFYiX"
      },
      "source": [
        "Only keep items that are clicked on by at least 5 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ytmY4lFYiX"
      },
      "source": [
        "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay8PGVQDFYia",
        "outputId": "d1a091a9-6d91-46d6-866a-a2424db2d78f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After filtering, there are 9990682 watching events from 136677 users and 20720 movies (sparsity: 0.353%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vientq_DFYic"
      },
      "source": [
        "unique_uid = user_activity.index\n",
        "\n",
        "np.random.seed(98765)\n",
        "idx_perm = np.random.permutation(unique_uid.size)\n",
        "unique_uid = unique_uid[idx_perm]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDe3B_KYFYif"
      },
      "source": [
        "# create train/validation/test users\n",
        "n_users = unique_uid.size\n",
        "n_heldout_users = 10000\n",
        "\n",
        "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "te_users = unique_uid[(n_users - n_heldout_users):]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60FBs88zFYih"
      },
      "source": [
        "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxCxoAh1FYik"
      },
      "source": [
        "unique_sid = pd.unique(train_plays['movieId'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCcfXDUvFYin"
      },
      "source": [
        "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKgIGJy1FYiq"
      },
      "source": [
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
        "\n",
        "if not os.path.exists(pro_dir):\n",
        "    os.makedirs(pro_dir)\n",
        "\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "    for sid in unique_sid:\n",
        "        f.write('%s\\n' % sid)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fG-zwHSFYis"
      },
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "\n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1k2d_g2FYiu"
      },
      "source": [
        "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJU3Ncf7FYiw",
        "outputId": "ca2593ae-77a4-4dae-e142-cec6d5579579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptvFIhlsFYiy"
      },
      "source": [
        "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX261EFPFYi1",
        "outputId": "871a77f5-b986-4d93-ae19-a30ee880597b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 users sampled\n",
            "1000 users sampled\n",
            "2000 users sampled\n",
            "3000 users sampled\n",
            "4000 users sampled\n",
            "5000 users sampled\n",
            "6000 users sampled\n",
            "7000 users sampled\n",
            "8000 users sampled\n",
            "9000 users sampled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfPenbm2FYi3"
      },
      "source": [
        "### Save the data into (user_index, item_index) format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfJU_gBkFYi3"
      },
      "source": [
        "def numerize(tp):\n",
        "    uid = map(lambda x: profile2id[x], tp['userId'])\n",
        "    sid = map(lambda x: show2id[x], tp['movieId'])\n",
        "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUTKUFEAFYi6"
      },
      "source": [
        "train_data = numerize(train_plays)\n",
        "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArJf0e8FYi8"
      },
      "source": [
        "vad_data_tr = numerize(vad_plays_tr)\n",
        "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugbb4-ThFYi_"
      },
      "source": [
        "vad_data_te = numerize(vad_plays_te)\n",
        "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_17Rkt3jFYjB"
      },
      "source": [
        "test_data_tr = numerize(test_plays_tr)\n",
        "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iG-vxzWFYjD"
      },
      "source": [
        "test_data_te = numerize(test_plays_te)\n",
        "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBJhcqMbFYjF"
      },
      "source": [
        "## Model definition and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlEMlH6TFYjF"
      },
      "source": [
        "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNtUyqeFYjF"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcrNQ2mYFYjG"
      },
      "source": [
        "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI37y0ciFYjG"
      },
      "source": [
        "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
        "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCD6bKYFYjH"
      },
      "source": [
        "The objective for Multi-DAE for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
        "$$\n",
        "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNHkjNS_FYjH"
      },
      "source": [
        "class MultiDAE(object):\n",
        "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
        "        self.p_dims = p_dims\n",
        "        if q_dims is None:\n",
        "            self.q_dims = p_dims[::-1]\n",
        "        else:\n",
        "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
        "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
        "            self.q_dims = q_dims\n",
        "        self.dims = self.q_dims + self.p_dims[1:]\n",
        "        \n",
        "        self.lam = lam\n",
        "        self.lr = lr\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.construct_placeholders()\n",
        "\n",
        "    def construct_placeholders(self):        \n",
        "        self.input_ph = tf.placeholder(\n",
        "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
        "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
        "\n",
        "    def build_graph(self):\n",
        "\n",
        "        self.construct_weights()\n",
        "\n",
        "        saver, logits = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        # per-user average negative log-likelihood\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph, axis=1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        reg_var = apply_regularization(reg, self.weights)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        loss = neg_ll + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('loss', loss)\n",
        "        merged = tf.summary.merge_all()\n",
        "        return saver, logits, loss, train_op, merged\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # construct forward graph        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return tf.train.Saver(), h\n",
        "\n",
        "    def construct_weights(self):\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        # define weights\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
        "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_{}\".format(i+1)\n",
        "            \n",
        "            self.weights.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases[-1])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYKe5hIIFYjK"
      },
      "source": [
        "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
        "$$\n",
        "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
        "$$\n",
        "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxGbnGCNFYjK"
      },
      "source": [
        "class MultiVAE(MultiDAE):\n",
        "\n",
        "    def construct_placeholders(self):\n",
        "        super(MultiVAE, self).construct_placeholders()\n",
        "\n",
        "        # placeholders with default values when scoring\n",
        "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
        "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
        "        \n",
        "    def build_graph(self):\n",
        "        self._construct_weights()\n",
        "\n",
        "        saver, logits, KL = self.forward_pass()\n",
        "        log_softmax_var = tf.nn.log_softmax(logits)\n",
        "\n",
        "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
        "            log_softmax_var * self.input_ph,\n",
        "            axis=-1))\n",
        "        # apply regularization to weights\n",
        "        reg = l2_regularizer(self.lam)\n",
        "        \n",
        "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
        "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
        "        # multiply 2 so that it is back in the same scale\n",
        "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
        "        \n",
        "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
        "\n",
        "        # add summary statistics\n",
        "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
        "        tf.summary.scalar('KL', KL)\n",
        "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
        "        merged = tf.summary.merge_all()\n",
        "\n",
        "        return saver, logits, neg_ELBO, train_op, merged\n",
        "    \n",
        "    def q_graph(self):\n",
        "        mu_q, std_q, KL = None, None, None\n",
        "        \n",
        "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
        "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_q) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "            else:\n",
        "                mu_q = h[:, :self.q_dims[-1]]\n",
        "                logvar_q = h[:, self.q_dims[-1]:]\n",
        "\n",
        "                std_q = tf.exp(0.5 * logvar_q)\n",
        "                KL = tf.reduce_mean(tf.reduce_sum(\n",
        "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
        "        return mu_q, std_q, KL\n",
        "\n",
        "    def p_graph(self, z):\n",
        "        h = z\n",
        "        \n",
        "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
        "            h = tf.matmul(h, w) + b\n",
        "            \n",
        "            if i != len(self.weights_p) - 1:\n",
        "                h = tf.nn.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def forward_pass(self):\n",
        "        # q-network\n",
        "        mu_q, std_q, KL = self.q_graph()\n",
        "        epsilon = tf.random_normal(tf.shape(std_q))\n",
        "\n",
        "        sampled_z = mu_q + self.is_training_ph *\\\n",
        "            epsilon * std_q\n",
        "\n",
        "        # p-network\n",
        "        logits = self.p_graph(sampled_z)\n",
        "        \n",
        "        return tf.train.Saver(), logits, KL\n",
        "\n",
        "    def _construct_weights(self):\n",
        "        self.weights_q, self.biases_q = [], []\n",
        "        \n",
        "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
        "            if i == len(self.q_dims[:-1]) - 1:\n",
        "                # we need two sets of parameters for mean and variance,\n",
        "                # respectively\n",
        "                d_out *= 2\n",
        "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_q_{}\".format(i+1)\n",
        "            \n",
        "            self.weights_q.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_q.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
        "            \n",
        "        self.weights_p, self.biases_p = [], []\n",
        "\n",
        "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
        "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
        "            bias_key = \"bias_p_{}\".format(i+1)\n",
        "            self.weights_p.append(tf.get_variable(\n",
        "                name=weight_key, shape=[d_in, d_out],\n",
        "                initializer=tf.contrib.layers.xavier_initializer(\n",
        "                    seed=self.random_seed)))\n",
        "            \n",
        "            self.biases_p.append(tf.get_variable(\n",
        "                name=bias_key, shape=[d_out],\n",
        "                initializer=tf.truncated_normal_initializer(\n",
        "                    stddev=0.001, seed=self.random_seed)))\n",
        "            \n",
        "            # add summary stats\n",
        "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
        "            tf.summary.histogram(bias_key, self.biases_p[-1])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODsCIU-fFYjM"
      },
      "source": [
        "### Training/validation data, hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGSGE8zeFYjM"
      },
      "source": [
        "Load the pre-processed training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEfmgezwFYjM"
      },
      "source": [
        "unique_sid = list()\n",
        "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
        "    for line in f:\n",
        "        unique_sid.append(line.strip())\n",
        "\n",
        "n_items = len(unique_sid)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhV3WVq4FYjO"
      },
      "source": [
        "def load_train_data(csv_file):\n",
        "    tp = pd.read_csv(csv_file)\n",
        "    n_users = tp['uid'].max() + 1\n",
        "\n",
        "    rows, cols = tp['uid'], tp['sid']\n",
        "    data = sparse.csr_matrix((np.ones_like(rows),\n",
        "                             (rows, cols)), dtype='float64',\n",
        "                             shape=(n_users, n_items))\n",
        "    return data"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmA2gNL3FYjQ"
      },
      "source": [
        "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1AhXPsNFYjR"
      },
      "source": [
        "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
        "    tp_tr = pd.read_csv(csv_file_tr)\n",
        "    tp_te = pd.read_csv(csv_file_te)\n",
        "\n",
        "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
        "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
        "\n",
        "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
        "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
        "\n",
        "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
        "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
        "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
        "    return data_tr, data_te"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di1oeGm2FYjT"
      },
      "source": [
        "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
        "                                           os.path.join(pro_dir, 'validation_te.csv'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk8iKyDzFYjV"
      },
      "source": [
        "Set up training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETG2JNpGFYjW"
      },
      "source": [
        "N = train_data.shape[0]\n",
        "idxlist = range(N)\n",
        "\n",
        "# training batch size\n",
        "batch_size = 1000\n",
        "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
        "\n",
        "N_vad = vad_data_tr.shape[0]\n",
        "idxlist_vad = range(N_vad)\n",
        "\n",
        "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
        "batch_size_vad = 2000\n",
        "\n",
        "# the total number of gradient updates for annealing\n",
        "total_anneal_steps = 200000\n",
        "# largest annealing parameter\n",
        "anneal_cap = 0.2"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9hAllGaFYjZ"
      },
      "source": [
        "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsRjxtjSFYjZ"
      },
      "source": [
        "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    '''\n",
        "    normalized discounted cumulative gain@k for binary relevance\n",
        "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
        "    '''\n",
        "    batch_users = X_pred.shape[0]\n",
        "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                       idx_topk_part[:, :k]]\n",
        "    idx_part = np.argsort(-topk_part, axis=1)\n",
        "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "    # topk predicted score\n",
        "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "    # build the discount template\n",
        "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
        "\n",
        "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                         idx_topk].toarray() * tp).sum(axis=1)\n",
        "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
        "                     for n in heldout_batch.getnnz(axis=1)])\n",
        "    return DCG / IDCG"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQz5SmxzFYjb"
      },
      "source": [
        "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
        "    batch_users = X_pred.shape[0]\n",
        "\n",
        "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
        "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
        "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
        "\n",
        "    X_true_binary = (heldout_batch > 0).toarray()\n",
        "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
        "        np.float32)\n",
        "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
        "    return recall"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3eDxiwkFYjd"
      },
      "source": [
        "### Train a Multi-VAE^{PR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XTyfWXXFYje"
      },
      "source": [
        "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxge_UC5FYje"
      },
      "source": [
        "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVZTnXauFYje"
      },
      "source": [
        "p_dims = [200, 600, n_items]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUwFoLhRFYjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452ef6f6-6029-48b2-bc46-15794f0e681b"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1202 00:56:23.860919 140263284406144 deprecation.py:506] From <ipython-input-31-318b0755b4c1>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W1202 00:56:24.024682 140263284406144 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1205: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yd73_vSFYjj"
      },
      "source": [
        "Set up logging and checkpoint directory\n",
        "\n",
        "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
        "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDzGG4VnFYjj"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HRfL9eXFYjl",
        "outputId": "b9bce6de-e32b-4a12-8537-59da475c9571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "log_dir = '/content/log/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /content/log/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onllv_KFFYjn",
        "outputId": "9c6f560c-67b7-456a-d0cd-7fe80e37a700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEUws3MBFYjo"
      },
      "source": [
        "n_epochs = 20"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xjH1qvYQ1t_"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ceanmc5-FYjr",
        "outputId": "4f349619-90c2-4db8-dae9-8d4fe3cb0ca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "\n",
        "    update_count = 0.0\n",
        "    \n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            if total_anneal_steps > 0:\n",
        "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "            else:\n",
        "                anneal = anneal_cap\n",
        "            \n",
        "            feed_dict = {vae.input_ph: X, \n",
        "                         vae.keep_prob_ph: 0.5, \n",
        "                         vae.anneal_ph: anneal,\n",
        "                         vae.is_training_ph: 1}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, \n",
        "                                           global_step=epoch * batches_per_epoch + bnum) \n",
        "            \n",
        "            update_count += 1\n",
        "        \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [06:39<00:00, 19.88s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LemP9VhNFYjt",
        "outputId": "3b103db5-c3e2-4331-f5d5-e94335eb29f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeMzPudfFYju"
      },
      "source": [
        "### Load the test data and compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsRAPEkFFYju"
      },
      "source": [
        "test_data_tr, test_data_te = load_tr_te_data(\n",
        "    os.path.join(pro_dir, 'test_tr.csv'),\n",
        "    os.path.join(pro_dir, 'test_te.csv'))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldrY0hJhFYjx"
      },
      "source": [
        "N_test = test_data_tr.shape[0]\n",
        "idxlist_test = range(N_test)\n",
        "\n",
        "batch_size_test = 2000"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKENimMVFYjz"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "vae = MultiVAE(p_dims, lam=0.0)\n",
        "saver, logits_var, _, _, _ = vae.build_graph()    "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZsTJ6wPFYj0"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkeAm-doFYj1",
        "outputId": "761fe790-d0a7-47b8-ac58-907e53c9ddf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chkpt_dir = '/content/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
        "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /content/chkpt/ml-20m/VAE_anneal200K_cap2.0E-01/I-600-200-600-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBd_FOB3FYj5",
        "outputId": "e1e892ad-e0f2-4a2a-8ceb-b5ce99baca9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "\n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "    \n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1202 01:03:07.320445 140263284406144 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5jiCJtjFYj6",
        "outputId": "11fd6271-3fed-495e-a25b-5374224902d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.40902 (0.00209)\n",
            "Test Recall@20=0.38090 (0.00270)\n",
            "Test Recall@50=0.52343 (0.00288)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_UQqKHTbW2Y"
      },
      "source": [
        "## Activity\n",
        "Train and test multi-DAE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt6c7n3vFYj8"
      },
      "source": [
        "### Train a Multi-DAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sxbccfxFYj8"
      },
      "source": [
        "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtERLP50FYj8"
      },
      "source": [
        "p_dims = [200, n_items]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj2JohEIFYj-"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
        "\n",
        "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
        "\n",
        "ndcg_var = tf.Variable(0.0)\n",
        "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
        "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
        "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
        "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oTDQAmdFYkA"
      },
      "source": [
        "Set up logging and checkpoint directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-47-HpT4FYkA"
      },
      "source": [
        "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ss1ShooFYkD",
        "outputId": "f684e91a-26e7-47e3-9b1d-ebd944c142d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "log_dir = '/volmount/log/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if os.path.exists(log_dir):\n",
        "    shutil.rmtree(log_dir)\n",
        "\n",
        "print(\"log directory: %s\" % log_dir)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log directory: /volmount/log/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHnoMeb2FYkF",
        "outputId": "ae56f0a9-1e4f-44ab-a09a-25661621b514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "\n",
        "if not os.path.isdir(chkpt_dir):\n",
        "    os.makedirs(chkpt_dir) \n",
        "    \n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXTkHeCwFYkH"
      },
      "source": [
        "n_epochs = 20"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUWc5lnHFYkI",
        "outputId": "7fe4a965-28c0-483d-a543-f24b310ffd9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ndcgs_vad = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    best_ndcg = -np.inf\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        print(epoch)\n",
        "        np.random.shuffle(idxlist)\n",
        "        # train for one epoch\n",
        "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
        "            end_idx = min(st_idx + batch_size, N)\n",
        "            X = train_data[idxlist[st_idx:end_idx]]\n",
        "            \n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')           \n",
        "            \n",
        "            feed_dict = {dae.input_ph: X, \n",
        "                         dae.keep_prob_ph: 0.5}        \n",
        "            sess.run(train_op_var, feed_dict=feed_dict)\n",
        "\n",
        "            if bnum % 100 == 0:\n",
        "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
        "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
        "                    \n",
        "        # compute validation NDCG\n",
        "        ndcg_dist = []\n",
        "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
        "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
        "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
        "\n",
        "            if sparse.isspmatrix(X):\n",
        "                X = X.toarray()\n",
        "            X = X.astype('float32')\n",
        "        \n",
        "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
        "            # exclude examples from training and validation (if any)\n",
        "            pred_val[X.nonzero()] = -np.inf\n",
        "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
        "        \n",
        "        ndcg_dist = np.concatenate(ndcg_dist)\n",
        "        ndcg_ = ndcg_dist.mean()\n",
        "        ndcgs_vad.append(ndcg_)\n",
        "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
        "        summary_writer.add_summary(merged_valid_val, epoch)\n",
        "\n",
        "        # update the best model (if necessary)\n",
        "        if ndcg_ > best_ndcg:\n",
        "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
        "            best_ndcg = ndcg_"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8sTDoZEFYkK",
        "outputId": "4ddc83d8-c6e4-4329-99e5-a1a1c60b39f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(ndcgs_vad)\n",
        "plt.ylabel(\"Validation NDCG@100\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "pass"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtAk0mYFYkM"
      },
      "source": [
        "### Compute test metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ8KXJslFYkN"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
        "saver, logits_var, _, _, _ = dae.build_graph()    "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_wplMBeFYkO"
      },
      "source": [
        "Load the best performing model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLyop0oFYkO",
        "outputId": "6ca77c9b-3393-46da-88bd-19a4ac9da08d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
        "print(\"chkpt directory: %s\" % chkpt_dir)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jONQoamqFYkQ"
      },
      "source": [
        "n100_list, r20_list, r50_list = [], [], []\n",
        "\n",
        "with tf.Session() as sess:    \n",
        "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "    \n",
        "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "        end_idx = min(st_idx + batch_size_test, N_test)\n",
        "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
        "\n",
        "        if sparse.isspmatrix(X):\n",
        "            X = X.toarray()\n",
        "        X = X.astype('float32')\n",
        "\n",
        "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
        "        # exclude examples from training and validation (if any)\n",
        "        pred_val[X.nonzero()] = -np.inf\n",
        "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
        "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
        "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
        "\n",
        "n100_list = np.concatenate(n100_list)\n",
        "r20_list = np.concatenate(r20_list)\n",
        "r50_list = np.concatenate(r50_list)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jUmIokmFYkR",
        "outputId": "2c8c29a0-eb25-4f03-a2dc-74633de36a30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
        "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
        "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NDCG@100=0.40849 (0.00210)\n",
            "Test Recall@20=0.37763 (0.00269)\n",
            "Test Recall@50=0.51542 (0.00287)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}